import numpy as np
import pandas as pd
import json
import pickle
from datetime import datetime
from collections import deque
import warnings
warnings.filterwarnings('ignore')

class QuantumDeepLearner:
    def __init__(self):
        self.learning_memory = deque(maxlen=10000)
        self.pattern_database = {}
        self.strategy_performance = {}
        self.market_regime_knowledge = {}
        self.learning_progress = 0
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self.load_knowledge_base()
    
    def recognize_patterns(self, market_data):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        patterns = {
            'trend_patterns': self.analyze_trend_patterns(market_data),
            'reversal_patterns': self.analyze_reversal_patterns(market_data),
            'consolidation_patterns': self.analyze_consolidation_patterns(market_data),
            'breakout_patterns': self.analyze_breakout_patterns(market_data),
            'confidence': 0.0
        }
        
        # Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© Ø§Ù„Ù†Ù…Ø·
        patterns['confidence'] = self.calculate_pattern_confidence(patterns)
        
        return patterns
    
    def analyze_trend_patterns(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        trends = {
            'uptrend_detected': False,
            'downtrend_detected': False,
            'trend_strength': 0.0,
            'trend_duration': 0,
            'acceleration': 0.0
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        for timeframe, data in market_data.items():
            if timeframe != 'symbol' and not data.empty:
                trend_analysis = self.calculate_trend_metrics(data)
                trends['uptrend_detected'] |= trend_analysis['is_uptrend']
                trends['downtrend_detected'] |= trend_analysis['is_downtrend']
                trends['trend_strength'] = max(trends['trend_strength'], trend_analysis['strength'])
                trends['acceleration'] = max(trends['acceleration'], trend_analysis['acceleration'])
        
        return trends
    
    def calculate_trend_metrics(self, data):
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        if len(data) < 20:
            return {'is_uptrend': False, 'is_downtrend': False, 'strength': 0.0, 'acceleration': 0.0}
        
        closes = data['close'].values
        
        # Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
        sma_20 = np.mean(closes[-20:])
        sma_50 = np.mean(closes[-min(50, len(closes)):])
        
        # Ù‚ÙˆØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        trend_strength = abs(sma_20 - sma_50) / sma_50
        
        # Ø§Ù„ØªØ³Ø§Ø±Ø¹
        recent_momentum = (closes[-1] / closes[-5] - 1) if len(closes) >= 5 else 0
        previous_momentum = (closes[-5] / closes[-10] - 1) if len(closes) >= 10 else 0
        acceleration = recent_momentum - previous_momentum
        
        return {
            'is_uptrend': sma_20 > sma_50,
            'is_downtrend': sma_20 < sma_50,
            'strength': trend_strength,
            'acceleration': acceleration
        }
    
    def analyze_reversal_patterns(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³"""
        reversals = {
            'potential_reversal': False,
            'reversal_type': None,  # 'bullish' or 'bearish'
            'confidence': 0.0,
            'trigger_level': 0.0
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©
        candle_patterns = self.analyze_candlestick_patterns(market_data)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù€ RSI divergence
        rsi_divergence = self.analyze_rsi_divergence(market_data)
        
        if candle_patterns['reversal_detected'] or rsi_divergence['divergence_detected']:
            reversals['potential_reversal'] = True
            reversals['confidence'] = max(candle_patterns['confidence'], rsi_divergence['confidence'])
            reversals['reversal_type'] = candle_patterns.get('reversal_type') or rsi_divergence.get('reversal_type')
        
        return reversals
    
    def analyze_candlestick_patterns(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©"""
        patterns = {
            'reversal_detected': False,
            'reversal_type': None,
            'confidence': 0.0
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø· Ù„Ù„Ø´Ù…ÙˆØ¹ (ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ù…ÙƒØªØ¨Ø© Ù…ØªØ®ØµØµØ©)
        for timeframe, data in market_data.items():
            if timeframe != 'symbol' and not data.empty and len(data) >= 3:
                recent_candles = data.tail(3)
                
                # Ù†Ù…Ø· engulfing
                if self.is_bullish_engulfing(recent_candles):
                    patterns['reversal_detected'] = True
                    patterns['reversal_type'] = 'bullish'
                    patterns['confidence'] = 0.7
                
                elif self.is_bearish_engulfing(recent_candles):
                    patterns['reversal_detected'] = True
                    patterns['reversal_type'] = 'bearish'
                    patterns['confidence'] = 0.7
        
        return patterns
    
    def is_bullish_engulfing(self, candles):
        """Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù†Ù…Ø· Ø§Ù„Ù€ Bullish Engulfing"""
        if len(candles) < 2:
            return False
        
        prev, curr = candles.iloc[-2], candles.iloc[-1]
        return (prev['close'] < prev['open'] and  # Ø´Ù…Ø¹Ø© Ù‡Ø§Ø¨Ø·Ø© Ø³Ø§Ø¨Ù‚Ø©
                curr['close'] > curr['open'] and  # Ø´Ù…Ø¹Ø© ØµØ§Ø¹Ø¯Ø© Ø­Ø§Ù„ÙŠØ©
                curr['open'] < prev['close'] and   # ÙØªØ­ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø£Ù‚Ù„ Ù…Ù† Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
                curr['close'] > prev['open'])      # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø£Ø¹Ù„Ù‰ Ù…Ù† ÙØªØ­ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    
    def is_bearish_engulfing(self, candles):
        """Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù†Ù…Ø· Ø§Ù„Ù€ Bearish Engulfing"""
        if len(candles) < 2:
            return False
        
        prev, curr = candles.iloc[-2], candles.iloc[-1]
        return (prev['close'] > prev['open'] and  # Ø´Ù…Ø¹Ø© ØµØ§Ø¹Ø¯Ø© Ø³Ø§Ø¨Ù‚Ø©
                curr['close'] < curr['open'] and  # Ø´Ù…Ø¹Ø© Ù‡Ø§Ø¨Ø·Ø© Ø­Ø§Ù„ÙŠØ©
                curr['open'] > prev['close'] and   # ÙØªØ­ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
                curr['close'] < prev['open'])      # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø£Ù‚Ù„ Ù…Ù† ÙØªØ­ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    
    def analyze_rsi_divergence(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù€ RSI divergence"""
        divergence = {
            'divergence_detected': False,
            'reversal_type': None,
            'confidence': 0.0
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø· Ù„Ù„Ù€ divergence
        for timeframe, data in market_data.items():
            if timeframe != 'symbol' and not data.empty and len(data) >= 20:
                rsi = self.calculate_rsi(data['close'], 14)
                prices = data['close'].values
                
                if len(rsi) >= 5:
                    # ØªØ­ divergence Ø¨ÙŠÙ† Ø§Ù„Ø³Ø¹Ø± ÙˆØ§Ù„Ù€ RSI
                    price_trend = prices[-1] - prices[-5]
                    rsi_trend = rsi[-1] - rsi[-5]
                    
                    if price_trend > 0 and rsi_trend < 0:  # bearish divergence
                        divergence['divergence_detected'] = True
                        divergence['reversal_type'] = 'bearish'
                        divergence['confidence'] = 0.6
                    
                    elif price_trend < 0 and rsi_trend > 0:  # bullish divergence
                        divergence['divergence_detected'] = True
                        divergence['reversal_type'] = 'bullish'
                        divergence['confidence'] = 0.6
        
        return divergence
    
    def calculate_rsi(self, prices, period=14):
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± RSI"""
        if len(prices) < period:
            return np.array([50] * len(prices))
        
        deltas = np.diff(prices)
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)
        
        avg_gains = np.convolve(gains, np.ones(period)/period, mode='valid')
        avg_losses = np.convolve(losses, np.ones(period)/period, mode='valid')
        
        rs = avg_gains / (avg_losses + 1e-10)
        rsi = 100 - (100 / (1 + rs))
        
        # Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ… Ù„Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø·ÙˆÙ„ prices
        rsi_full = np.concatenate([np.array([50] * (len(prices) - len(rsi))), rsi])
        
        return rsi_full
    
    def analyze_consolidation_patterns(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¬Ù…ÙŠØ¹"""
        consolidation = {
            'in_consolidation': False,
            'consolidation_range': 0.0,
            'breakout_direction': None,
            'breakout_probability': 0.0
        }
        
        for timeframe, data in market_data.items():
            if timeframe != 'symbol' and not data.empty and len(data) >= 20:
                volatility = self.calculate_volatility(data)
                price_range = (data['high'].max() - data['low'].min()) / data['close'].mean()
                
                if volatility < 0.02 and price_range < 0.05:  # ØªÙ‚Ù„Ø¨ Ù…Ù†Ø®ÙØ¶ ÙˆÙ†Ø·Ø§Ù‚ Ø³Ø¹Ø±ÙŠ Ø¶ÙŠÙ‚
                    consolidation['in_consolidation'] = True
                    consolidation['consolidation_range'] = price_range
                    consolidation['breakout_probability'] = self.calculate_breakout_probability(data)
        
        return consolidation
    
    def analyze_breakout_patterns(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚"""
        breakout = {
            'breakout_imminent': False,
            'expected_direction': None,
            'confidence': 0.0,
            'target_levels': {'short_term': 0, 'medium_term': 0}
        }
        
        for timeframe, data in market_data.items():
            if timeframe != 'symbol' and not data.empty and len(data) >= 30:
                # ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
                support, resistance = self.identify_support_resistance(data)
                current_price = data['close'].iloc[-1]
                
                # ØªØ­Ø¯ÙŠØ¯ Ù‚Ø±Ø¨ Ø§Ù„Ø³Ø¹Ø± Ù…Ù† Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø­Ø±Ø¬Ø©
                distance_to_resistance = abs(resistance - current_price) / current_price
                distance_to_support = abs(support - current_price) / current_price
                
                if distance_to_resistance < 0.01:  # Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
                    breakout['breakout_imminent'] = True
                    breakout['expected_direction'] = 'bullish' if self.is_strong_bullish_momentum(data) else 'bearish'
                    breakout['confidence'] = 0.7
                
                elif distance_to_support < 0.01:  # Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ø¯Ø¹Ù…
                    breakout['breakout_imminent'] = True
                    breakout['expected_direction'] = 'bullish' if self.is_strong_bullish_momentum(data) else 'bearish'
                    breakout['confidence'] = 0.7
        
        return breakout
    
    def calculate_volatility(self, data):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨"""
        returns = data['close'].pct_change().dropna()
        return returns.std() * np.sqrt(365)  # ØªÙ‚Ù„Ø¨ Ø³Ù†ÙˆÙŠ
    
    def calculate_breakout_probability(self, data):
        """Ø­Ø³Ø§Ø¨ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚"""
        if len(data) < 20:
            return 0.5
        
        # Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø±Ø© ÙÙŠ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚
        volume_trend = self.analyze_volume_trend(data)
        volatility_compression = self.analyze_volatility_compression(data)
        time_in_consolidation = min(len(data) / 50, 1.0)  # Ù†Ø³Ø¨Ø© Ø§Ù„ÙˆÙ‚Øª ÙÙŠ Ø§Ù„ØªØ¬Ù…ÙŠØ¹
        
        probability = (volume_trend * 0.4 + volatility_compression * 0.3 + time_in_consolidation * 0.3)
        return min(probability, 1.0)
    
    def analyze_volume_trend(self, data):
        """ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø­Ø¬Ù…"""
        if len(data) < 10:
            return 0.5
        
        volumes = data['volume'].values
        recent_volume = np.mean(volumes[-5:])
        previous_volume = np.mean(volumes[-10:-5])
        
        if previous_volume == 0:
            return 0.5
        
        volume_ratio = recent_volume / previous_volume
        return min(volume_ratio / 2, 1.0)  # ØªØ·Ø¨ÙŠØ¹
    
    def analyze_volatility_compression(self, data):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù†Ø¶ØºØ§Ø· Ø§Ù„ØªÙ‚Ù„Ø¨"""
        if len(data) < 20:
            return 0.5
        
        recent_volatility = self.calculate_volatility(data.tail(10))
        historical_volatility = self.calculate_volatility(data)
        
        if historical_volatility == 0:
            return 0.5
        
        compression_ratio = recent_volatility / historical_volatility
        return 1 - min(compression_ratio, 1.0)  # Ø§Ù†Ø¶ØºØ§Ø· Ø£Ø¹Ù„Ù‰ = Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ø®ØªØ±Ø§Ù‚ Ø£Ø¹Ù„Ù‰
    
    def identify_support_resistance(self, data):
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©"""
        if len(data) < 20:
            return data['low'].min(), data['high'].max()
        
        # Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø³Ø·Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
        support = data['low'].tail(20).min()
        resistance = data['high'].tail(20).max()
        
        return support, resistance
    
    def is_strong_bullish_momentum(self, data):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø²Ø®Ù… ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"""
        if len(data) < 10:
            return False
        
        recent_gain = (data['close'].iloc[-1] / data['close'].iloc[-5] - 1)
        volume_increase = (data['volume'].iloc[-1] / data['volume'].iloc[-5] - 1)
        
        return recent_gain > 0.02 and volume_increase > 0.1
    
    def calculate_pattern_confidence(self, patterns):
        """Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©"""
        confidence_factors = []
        
        if patterns['trend_patterns']['trend_strength'] > 0.1:
            confidence_factors.append(0.3)
        
        if patterns['reversal_patterns']['confidence'] > 0:
            confidence_factors.append(patterns['reversal_patterns']['confidence'] * 0.3)
        
        if patterns['consolidation_patterns']['breakout_probability'] > 0.6:
            confidence_factors.append(0.2)
        
        if patterns['breakout_patterns']['confidence'] > 0:
            confidence_factors.append(patterns['breakout_patterns']['confidence'] * 0.2)
        
        return sum(confidence_factors) if confidence_factors else 0.0
    
    def update_learning(self, recent_trades, market_data):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø©"""
        for trade in recent_trades:
            learning_insight = {
                'trade_data': trade,
                'market_conditions': self.extract_market_conditions(trade, market_data),
                'outcome': 'WIN' if trade['execution_result']['profit'] > 0 else 'LOSS',
                'timestamp': datetime.now(),
                'lessons_learned': self.extract_lessons(trade)
            }
            
            self.learning_memory.append(learning_insight)
            self.update_strategy_performance(learning_insight)
        
        self.learning_progress = min(len(self.learning_memory) / 1000, 1.0)
    
    def extract_market_conditions(self, trade, market_data):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¸Ø±ÙˆÙ Ø§Ù„Ø³ÙˆÙ‚ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØµÙÙ‚Ø©"""
        symbol = trade['symbol']
        if symbol in market_data:
            data = market_data[symbol]
            return {
                'trend_strength': self.calculate_trend_metrics(data)['strength'],
                'volatility': self.calculate_volatility(data),
                'volume_profile': self.analyze_volume_profile(data),
                'market_regime': self.classify_market_regime(data)
            }
        return {}
    
    def analyze_volume_profile(self, data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø­Ø¬Ù…"""
        if len(data) < 10:
            return 'UNKNOWN'
        
        recent_volume = data['volume'].tail(5).mean()
        historical_volume = data['volume'].mean()
        
        if recent_volume > historical_volume * 1.5:
            return 'HIGH_VOLUME'
        elif recent_volume < historical_volume * 0.5:
            return 'LOW_VOLUME'
        else:
            return 'NORMAL_VOLUME'
    
    def classify_market_regime(self, data):
        """ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³ÙˆÙ‚ÙŠ"""
        volatility = self.calculate_volatility(data)
        trend_strength = self.calculate_trend_metrics(data)['strength']
        
        if volatility > 0.03:
            return 'HIGH_VOLATILITY'
        elif trend_strength > 0.05:
            return 'TRENDING'
        else:
            return 'SIDEWAYS'
    
    def extract_lessons(self, trade):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„ØµÙÙ‚Ø©"""
        profit = trade['execution_result']['profit']
        expected_profit = trade.get('expected_profit', 0)
        
        lessons = []
        
        if profit > 0:
            if profit > expected_profit * 1.2:
                lessons.append("STRONG_SIGNAL_CONFIRMATION")
            else:
                lessons.append("MODERATE_SUCCESS")
        else:
            if abs(profit) > trade.get('max_loss', 0) * 0.8:
                lessons.append("RISK_MANAGEMENT_WORKED")
            else:
                lessons.append("NEED_BETTER_ENTRY")
        
        return lessons
    
    def update_strategy_performance(self, learning_insight):
        """ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª"""
        strategy = learning_insight['trade_data'].get('strategy', 'default')
        outcome = learning_insight['outcome']
        
        if strategy not in self.strategy_performance:
            self.strategy_performance[strategy] = {'wins': 0, 'losses': 0, 'total_profit': 0}
        
        if outcome == 'WIN':
            self.strategy_performance[strategy]['wins'] += 1
            self.strategy_performance[strategy]['total_profit'] += learning_insight['trade_data']['execution_result']['profit']
        else:
            self.strategy_performance[strategy]['losses'] += 1
            self.strategy_performance[strategy]['total_profit'] += learning_insight['trade_data']['execution_result']['profit']
    
    def get_best_strategies(self, top_n=3):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø£Ø¯Ø§Ø¡Ù‹"""
        if not self.strategy_performance:
            return []
        
        strategies = []
        for strategy, performance in self.strategy_performance.items():
            total_trades = performance['wins'] + performance['losses']
            win_rate = performance['wins'] / total_trades if total_trades > 0 else 0
            avg_profit = performance['total_profit'] / total_trades if total_trades > 0 else 0
            
            strategies.append({
                'strategy': strategy,
                'win_rate': win_rate,
                'avg_profit': avg_profit,
                'total_trades': total_trades,
                'score': win_rate * avg_profit * min(total_trades / 10, 1.0)
            })
        
        strategies.sort(key=lambda x: x['score'], reverse=True)
        return strategies[:top_n]
    
    def save_model(self):
        """Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù…"""
        try:
            knowledge = {
                'learning_memory': list(self.learning_memory),
                'pattern_database': self.pattern_database,
                'strategy_performance': self.strategy_performance,
                'market_regime_knowledge': self.market_regime_knowledge,
                'learning_progress': self.learning_progress,
                'last_updated': datetime.now().isoformat()
            }
            
            with open('data/models/quantum_knowledge.pkl', 'wb') as f:
                pickle.dump(knowledge, f)
            
            print("ğŸ’¾ Quantum learning model saved")
        except Exception as e:
            print(f"âš ï¸ Error saving quantum model: {e}")
    
    def load_knowledge_base(self):
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        try:
            with open('data/models/quantum_knowledge.pkl', 'rb') as f:
                knowledge = pickle.load(f)
                
            self.learning_memory = deque(knowledge.get('learning_memory', []), maxlen=10000)
            self.pattern_database = knowledge.get('pattern_database', {})
            self.strategy_performance = knowledge.get('strategy_performance', {})
            self.market_regime_knowledge = knowledge.get('market_regime_knowledge', {})
            self.learning_progress = knowledge.get('learning_progress', 0)
            
            print("ğŸ§  Quantum knowledge base loaded")
        except:
            print("ğŸ†• Starting with fresh quantum knowledge")
